\documentclass[]{article}
\usepackage{lmodern}
\usepackage{amssymb,amsmath}
\usepackage{ifxetex,ifluatex}
\usepackage{fixltx2e} % provides \textsubscript
\ifnum 0\ifxetex 1\fi\ifluatex 1\fi=0 % if pdftex
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
\else % if luatex or xelatex
  \ifxetex
    \usepackage{mathspec}
  \else
    \usepackage{fontspec}
  \fi
  \defaultfontfeatures{Ligatures=TeX,Scale=MatchLowercase}
\fi
% use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
% use microtype if available
\IfFileExists{microtype.sty}{%
\usepackage{microtype}
\UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\usepackage[margin=1in]{geometry}
\usepackage{hyperref}
\hypersetup{unicode=true,
            pdftitle={Ethereum Token Analysis},
            pdfauthor={Pushpita Panigrahi(pxp171530), Akash Chand(axc173730), Siddharth Swarup Panda(ssp171730)},
            pdfborder={0 0 0},
            breaklinks=true}
\urlstyle{same}  % don't use monospace font for urls
\usepackage{color}
\usepackage{fancyvrb}
\newcommand{\VerbBar}{|}
\newcommand{\VERB}{\Verb[commandchars=\\\{\}]}
\DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
% Add ',fontsize=\small' for more characters per line
\usepackage{framed}
\definecolor{shadecolor}{RGB}{248,248,248}
\newenvironment{Shaded}{\begin{snugshade}}{\end{snugshade}}
\newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{#1}}
\newcommand{\DecValTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\FloatTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\CharTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\StringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\ImportTok}[1]{#1}
\newcommand{\CommentTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\OtherTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{#1}}
\newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\VariableTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.81,0.36,0.00}{\textbf{#1}}}
\newcommand{\BuiltInTok}[1]{#1}
\newcommand{\ExtensionTok}[1]{#1}
\newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.77,0.63,0.00}{#1}}
\newcommand{\RegionMarkerTok}[1]{#1}
\newcommand{\InformationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\WarningTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\AlertTok}[1]{\textcolor[rgb]{0.94,0.16,0.16}{#1}}
\newcommand{\ErrorTok}[1]{\textcolor[rgb]{0.64,0.00,0.00}{\textbf{#1}}}
\newcommand{\NormalTok}[1]{#1}
\usepackage{graphicx,grffile}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
\IfFileExists{parskip.sty}{%
\usepackage{parskip}
}{% else
\setlength{\parindent}{0pt}
\setlength{\parskip}{6pt plus 2pt minus 1pt}
}
\setlength{\emergencystretch}{3em}  % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\setcounter{secnumdepth}{0}
% Redefines (sub)paragraphs to behave more like sections
\ifx\paragraph\undefined\else
\let\oldparagraph\paragraph
\renewcommand{\paragraph}[1]{\oldparagraph{#1}\mbox{}}
\fi
\ifx\subparagraph\undefined\else
\let\oldsubparagraph\subparagraph
\renewcommand{\subparagraph}[1]{\oldsubparagraph{#1}\mbox{}}
\fi

%%% Use protect on footnotes to avoid problems with footnotes in titles
\let\rmarkdownfootnote\footnote%
\def\footnote{\protect\rmarkdownfootnote}

%%% Change title format to be more compact
\usepackage{titling}

% Create subtitle command for use in maketitle
\newcommand{\subtitle}[1]{
  \posttitle{
    \begin{center}\large#1\end{center}
    }
}

\setlength{\droptitle}{-2em}

  \title{Ethereum Token Analysis}
    \pretitle{\vspace{\droptitle}\centering\huge}
  \posttitle{\par}
    \author{Pushpita Panigrahi(pxp171530), Akash Chand(axc173730), Siddharth Swarup
Panda(ssp171730)}
    \preauthor{\centering\large\emph}
  \postauthor{\par}
    \date{}
    \predate{}\postdate{}
  

\begin{document}
\maketitle

\subsection{Introduction}\label{introduction}

\subsubsection{Blockchain Technology}\label{blockchain-technology}

Block chain is a growing list of records, called blocks, which are
linked using cryptography (cryptography is the practice and study of
techniques for secure communication in the presence of third parties)
.Each block contains a cryptographic hash of the previous block, a
timestamp, and transaction data. \emph{``The blockchain is an
incorruptible digital ledger of economic transactions that can be
programmed to record not just financial transactions but virtually
everything of value.''} It is an open, distributed ledger (a consensus
of replicated, shared, and synchronized digital data geographically
spread across multiple sites) that can record transactions between two
parties efficiently and in a verifiable and permanent way``. A
blockchain is typically managed by a peer-to-peer network collectively
adhering to a protocol for inter-node communication and validating new
blocks. Once recorded, the data in any given block cannot be altered
without alterating all its subsequent blocks, which requires consensus
of the network majority.

\subsubsection{Ethereum}\label{ethereum}

Ethereum is a distributed public block chain network that focuses on
running programming code of any decentralized application. More simply,
it is a platform for sharing information across the globe that cannot be
manipulated or changed. Ether, a decentralized digital currency, also
known as ETH is a cryptocurrency whose blockchain is generated by the
Ethereum platform. In addition to being a tradeable cryptocurrency,
ether powers the Ethereum network by paying for transaction fees and
computational services. As with other cryptocurrencies, the validity of
each ether is provided by a blockchain, which is a continuously growing
list of records, called blocks, which are linked and secured using
cryptography. Unlike Bitcoin, Ethereum operates using accounts and
balances in a manner called state transitions.

\textbf{ERC-20} is a technical standard used for smart contracts on the
Ethereum blockchain for implementing tokens. ERC stands for Ethereum
Request for Comment, and 20 is the number that was assigned to this
request.ERC-20 defines a common list of rules for Ethereum tokens to
follow within the larger Ethereum ecosystem, allowing developers to
accurately predict interaction between tokens. These rules include how
the tokens are transferred between addresses and how data within each
token is accessed

\subsubsection{BNB Token}\label{bnb-token}

We chose Binance coin(networkbnbTX) token as our dataset. There are
typically two different types of exchanges: the ones that deal with fiat
currency and the ones that deal purely in crypto. The latter one even
though they are small now, it is expected that pure crypto exchanges
will have a bigger impact than fiat based exchanges in the near future.
They will play an ever more important role in world finance and this new
paradigm is called as Binance; Binary Finance. Features of Binance
include : 1) Safety Stability - Multi-tier \& multi-cluster system
architecture 2) High Performance - Capable of processing 1,400,000
orders per second 3) High Liquidity - Abundant resources and partners 4)
All Devices Covered - Web, Android, iOS, Mobile Web, Windows, macOS 5)
Multilingual Support - Support and FAQs available in multiple languages
6) Multiple-Coin Support - BTC, ETH, LTC, BNB

\subsection{Steps}\label{steps}

\subsubsection{Data preparation and
preprocessing}\label{data-preparation-and-preprocessing}

The networkbnbTX file is read into a dataframe. We get the total supply
and possible sub units of BNB token in market from
www.coinmarketcap.com. Token edge files have following row structure:
\textbf{fromNodeID, toNodeID, unixTime, tokenAmount}. Each row implies
that \emph{fromNodeID} sold tokenAmount of the token to \emph{toNodeID}
at time \emph{unixTime}. \emph{fromNodeID} and \emph{toNodeID} are ids
for people who invest in the token in real life. Each person can use
multiple ids and 2 ids can sell/buy tokens multiple times with multiple
amounts. This makes our network a weighted, directed, multiedge graph.
Below is the sample data from the network file:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(plyr)}
\KeywordTok{library}\NormalTok{(ggplot2) }
\KeywordTok{library}\NormalTok{(fitdistrplus)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Loading required package: MASS
\end{verbatim}

\begin{verbatim}
## Loading required package: survival
\end{verbatim}

\begin{verbatim}
## Loading required package: npsurv
\end{verbatim}

\begin{verbatim}
## Loading required package: lsei
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{require}\NormalTok{(plyr)}
\KeywordTok{library}\NormalTok{(grid)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{file <-}\StringTok{'networkbnbTX.txt'}
\NormalTok{col_names <-}\StringTok{ }\KeywordTok{c}\NormalTok{(}\StringTok{"FROMNODE"}\NormalTok{,}\StringTok{"TONODE"}\NormalTok{,}\StringTok{"DATE"}\NormalTok{,}\StringTok{"TOKENAMOUNT"}\NormalTok{)}
\NormalTok{mydata <-}\StringTok{ }\KeywordTok{read.csv}\NormalTok{( file, }\DataTypeTok{header =} \OtherTok{FALSE}\NormalTok{, }\DataTypeTok{sep =} \StringTok{" "}\NormalTok{, }\DataTypeTok{dec =} \StringTok{"."}\NormalTok{, }\DataTypeTok{col.names =}\NormalTok{ col_names)}
\NormalTok{mydata}\OperatorTok{$}\NormalTok{DATE <-}\StringTok{ }\KeywordTok{as.Date}\NormalTok{(}\KeywordTok{as.POSIXct}\NormalTok{(}\KeywordTok{as.numeric}\NormalTok{(mydata}\OperatorTok{$}\NormalTok{DATE), }\DataTypeTok{origin =} \StringTok{'1970-01-01'}\NormalTok{, }\DataTypeTok{tz =} \StringTok{'GMT'}\NormalTok{))}
\NormalTok{amounts <-}\StringTok{ }\NormalTok{mydata[}\DecValTok{4}\NormalTok{]}

\NormalTok{totalSupply <-}\StringTok{ }\DecValTok{192443301}
\NormalTok{subUnits <-}\StringTok{ }\DecValTok{18}
\NormalTok{totalAmount <-}\StringTok{ }\NormalTok{totalSupply }\OperatorTok{*}\StringTok{ }\NormalTok{(}\DecValTok{10} \OperatorTok{^}\StringTok{ }\NormalTok{subUnits)}
\CommentTok{#head(mydata)}
\end{Highlighting}
\end{Shaded}

The price file for BNB token is read into a dataframe which contains the
open, clase, max and min price for the token foe each day. The row
structure of the file is \textbf{Date, Open, High, Low, Close, Volume,
MarketCap}. \emph{Open} and \emph{close} are the prices of the specific
token at each day. \emph{Volume} gives total bought/sold tokens and
\emph{MarketCap} gives the market valuation at each day. Below is a
sample data of the price file:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{pricefile <-}\StringTok{'bnb.txt'}
\NormalTok{col_names <-}\StringTok{ }\KeywordTok{c}\NormalTok{(}\StringTok{"Date"}\NormalTok{,}\StringTok{"Open"}\NormalTok{,}\StringTok{"High"}\NormalTok{,}\StringTok{"Low"}\NormalTok{,}\StringTok{"Close"}\NormalTok{,}\StringTok{"Volume"}\NormalTok{,}\StringTok{"MarketCap"}\NormalTok{)}
\NormalTok{myPrices <-}\StringTok{ }\KeywordTok{read.csv}\NormalTok{( pricefile , }\DataTypeTok{header =} \OtherTok{TRUE}\NormalTok{, }\DataTypeTok{sep =} \StringTok{"}\CharTok{\textbackslash{}t}\StringTok{"}\NormalTok{, }\DataTypeTok{dec =} \StringTok{"."}\NormalTok{, }\DataTypeTok{col.names =}\NormalTok{ col_names)}
\NormalTok{myPrices}\OperatorTok{$}\NormalTok{Date <-}\StringTok{ }\KeywordTok{format}\NormalTok{(}\KeywordTok{as.Date}\NormalTok{(myPrices}\OperatorTok{$}\NormalTok{Date, }\DataTypeTok{format =} \StringTok{"%m/%d/%Y"}\NormalTok{), }\StringTok{"%Y-%m-%d"}\NormalTok{)}
\CommentTok{#head(myPrices)}
\end{Highlighting}
\end{Shaded}

\subsubsection{Preprocessing}\label{preprocessing}

The preprocessing step involves removal of fraudulent transactions which
might affect the distribution estimate negatively. The total supply of
the networkbnb token is 192443301 (quoted from etherscan.io) and the
range of subunits for the token is 18 decimal units. Thus any
transaction having that attempts to log a value, i.e,
\emph{tokenAmount}, greater than the product of total supply and
subunits is deemed as fraudulent. \textbf{Result: }The token networkbnb
does not have any fraudulent transactions.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{temp <-}\StringTok{ }\KeywordTok{which}\NormalTok{(mydata}\OperatorTok{<}\StringTok{ }\NormalTok{totalAmount)}
\CommentTok{#print meta data }
\KeywordTok{message}\NormalTok{(}\StringTok{'Maximum allowed amount : '}\NormalTok{, totalAmount)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Maximum allowed amount : 1.92443301e+26
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{count <-}\StringTok{ }\DecValTok{0}
\NormalTok{outliers <-}\StringTok{ }\DecValTok{0}
\ControlFlowTok{for}\NormalTok{( a }\ControlFlowTok{in} \DecValTok{1}\OperatorTok{:}\KeywordTok{nrow}\NormalTok{(amounts))\{}
  \ControlFlowTok{if}\NormalTok{( a }\OperatorTok{>}\StringTok{ }\NormalTok{totalAmount)\{}
\NormalTok{    outliers <-}\StringTok{ }\NormalTok{outliers }\OperatorTok{+}\StringTok{ }\DecValTok{1}
\NormalTok{  \}}
  \ControlFlowTok{else}\NormalTok{\{}
\NormalTok{    count <-}\StringTok{ }\NormalTok{count }\OperatorTok{+}\StringTok{ }\DecValTok{1}
\NormalTok{  \}}
\NormalTok{\}}
\KeywordTok{message}\NormalTok{(}\StringTok{'Number of fradulent transactions : '}\NormalTok{,outliers)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Number of fradulent transactions : 0
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{message}\NormalTok{(}\StringTok{'Number of valid amounts : '}\NormalTok{,count)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Number of valid amounts : 357142
\end{verbatim}

\subsubsection{Package used to fit
distributions}\label{package-used-to-fit-distributions}

For approximating distributions, descdist R function is used which
provides a Cullen and Frey skewness-kurtosis plot. Bootstrapped samples
of the data have been used in order to consider the uncertainty of the
estimated skewness and kurtosis values which are higher order moments.
Skewness is a measure of symmetry while kurtosis is the measure of the
combined weight of distribution's tails relative to the center of the
distribution, which is why both the statistics are dependable to
estimate the distribution of the data.

\subsubsection{Function to remove
outliers}\label{function-to-remove-outliers}

The data points which fall outside 2.5 times the inter-quartile range
are considered as outliers and are removed from the dataset. We tested
our experiments with values 1, 1,5, 2, 2.5, 3 times the IQR and found
the best results with 2.5 IQR value. We believe this is because we need
a significant number of data points to fit our distributions.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{remove_outliers <-}\StringTok{ }\ControlFlowTok{function}\NormalTok{(x, }\DataTypeTok{na.rm =} \OtherTok{TRUE}\NormalTok{, ...) \{}
\NormalTok{  qnt <-}\StringTok{ }\KeywordTok{quantile}\NormalTok{(x, }\DataTypeTok{probs=}\KeywordTok{c}\NormalTok{(.}\DecValTok{25}\NormalTok{, .}\DecValTok{75}\NormalTok{), }\DataTypeTok{na.rm =}\NormalTok{ na.rm, ...)}
\NormalTok{  H <-}\StringTok{ }\FloatTok{2.5} \OperatorTok{*}\StringTok{ }\KeywordTok{IQR}\NormalTok{(x, }\DataTypeTok{na.rm =}\NormalTok{ na.rm)}
\NormalTok{  y <-}\StringTok{ }\NormalTok{x}
\NormalTok{  y[x }\OperatorTok{<}\StringTok{ }\NormalTok{(qnt[}\DecValTok{1}\NormalTok{] }\OperatorTok{-}\StringTok{ }\NormalTok{H)] <-}\StringTok{ }\OtherTok{NA}
\NormalTok{  y[x }\OperatorTok{>}\StringTok{ }\NormalTok{(qnt[}\DecValTok{2}\NormalTok{] }\OperatorTok{+}\StringTok{ }\NormalTok{H)] <-}\StringTok{ }\OtherTok{NA}
\NormalTok{  y}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

\subsection{Study 1:}\label{study-1}

The aim of this experiment is to find a distribution of how many times
the user id transacts in BNB token. We find the frequencies of buys and
sells separately for each user and try to fit a distribution for the
frequencies. This helps us understand the transaction patterns user wise
for our token. Below is the statistics of the frequency distribution and
visualisation of the count of frequencies. This helps us understand how
likely it is to retain users using the token.

\subsubsection{Calculating and plotting selling
frequency}\label{calculating-and-plotting-selling-frequency}

\begin{verbatim}
## Using freq as weighting variable
\end{verbatim}

\includegraphics{Report_files/figure-latex/pressure-1.pdf}

\subsubsection{Removing outliers and summarizing
data}\label{removing-outliers-and-summarizing-data}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{newSet1 <-}\StringTok{ }\KeywordTok{remove_outliers}\NormalTok{(countFromFf}\OperatorTok{$}\NormalTok{Sell_Count)}
\NormalTok{maxCount1 =}\StringTok{ }\KeywordTok{max}\NormalTok{(newSet1[}\KeywordTok{complete.cases}\NormalTok{(newSet1)])}
\NormalTok{minCount1 =}\StringTok{ }\KeywordTok{min}\NormalTok{(newSet1[}\KeywordTok{complete.cases}\NormalTok{(newSet1)])}
\NormalTok{countFromFf <-}\StringTok{ }\KeywordTok{subset}\NormalTok{(countFromFf, Sell_Count}\OperatorTok{<}\NormalTok{maxCount1 }\OperatorTok{&}\StringTok{ }\NormalTok{Sell_Count}\OperatorTok{>}\NormalTok{minCount1)}
\KeywordTok{head}\NormalTok{(countFromFf)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##   Users_Count Sell_Count
## 4           4       1284
## 5           5        870
## 6           6        702
## 7           7        588
## 8           8        392
## 9           9        504
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{#descdist(countFromFf$Sell_Count, boot= 500, discrete=TRUE)}
\KeywordTok{descdist}\NormalTok{(countFromFf}\OperatorTok{$}\NormalTok{Sell_Count, }\DataTypeTok{boot=} \DecValTok{500}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{Report_files/figure-latex/unnamed-chunk-6-1.pdf}

\begin{verbatim}
## summary statistics
## ------
## min:  74   max:  1375 
## median:  373.5 
## mean:  431.3773 
## estimated sd:  240.2746 
## estimated skewness:  1.351751 
## estimated kurtosis:  5.142384
\end{verbatim}

\subsubsection{Approximating the selling
distributions}\label{approximating-the-selling-distributions}

From the above Cullen and Frey graph we could narrow down our
distribution selection to Weibull, lognormal, gamma and poisson.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{distributionFit_Seller_pois <-}\StringTok{ }\KeywordTok{fitdist}\NormalTok{(countFromFf}\OperatorTok{$}\NormalTok{Sell_Count, }\StringTok{"pois"}\NormalTok{, }\DataTypeTok{method =}\StringTok{"mle"}\NormalTok{)}
\NormalTok{distributionFit_Seller_wb <-}\StringTok{ }\KeywordTok{fitdist}\NormalTok{(countFromFf}\OperatorTok{$}\NormalTok{Sell_Count, }\StringTok{"weibull"}\NormalTok{, }\DataTypeTok{method =}\StringTok{"mle"}\NormalTok{)}
\NormalTok{distributionFit_Seller_ln <-}\StringTok{ }\KeywordTok{fitdist}\NormalTok{(countFromFf}\OperatorTok{$}\NormalTok{Sell_Count, }\StringTok{"lnorm"}\NormalTok{, }\DataTypeTok{method =}\StringTok{"mle"}\NormalTok{)}
\NormalTok{distributionFit_Seller_gm <-}\StringTok{ }\KeywordTok{fitdist}\NormalTok{(countFromFf}\OperatorTok{$}\NormalTok{Sell_Count, }\StringTok{"gamma"}\NormalTok{ ,}\DataTypeTok{method=}\StringTok{"mme"}\NormalTok{)}
\CommentTok{#distributionFit_Seller_wb$loglik}
\CommentTok{#plot(distributionFit_Seller_wb)}
\CommentTok{#distributionFit_Seller_pois$loglik}
\CommentTok{#plot(distributionFit_Seller_pois)}
\CommentTok{#distributionFit_Seller_ln$loglik}
\CommentTok{#plot(distributionFit_Seller_ln)}
\CommentTok{#distributionFit_Seller_gm$loglik}
\CommentTok{#plot(distributionFit_Seller_gm)}
\end{Highlighting}
\end{Shaded}

\subsubsection{Calculating and plotting buying
frequency}\label{calculating-and-plotting-buying-frequency}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{countToDf <-}\StringTok{ }\KeywordTok{count}\NormalTok{(mydata, }\StringTok{"TONODE"}\NormalTok{)}
\NormalTok{countToFf <-}\StringTok{ }\KeywordTok{count}\NormalTok{(countToDf, }\StringTok{"freq"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Using freq as weighting variable
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{colnames}\NormalTok{(countToFf) <-}\StringTok{ }\KeywordTok{c}\NormalTok{(}\StringTok{"Users_Count"}\NormalTok{, }\StringTok{"Buy_Count"}\NormalTok{)}
\KeywordTok{plot}\NormalTok{(countToFf}\OperatorTok{$}\NormalTok{Users_Count, countToFf}\OperatorTok{$}\NormalTok{Buy_Count)}
\end{Highlighting}
\end{Shaded}

\includegraphics{Report_files/figure-latex/unnamed-chunk-8-1.pdf}

\subsubsection{Removing outliers and summarizing
data}\label{removing-outliers-and-summarizing-data-1}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{newSet2 <-}\StringTok{ }\KeywordTok{remove_outliers}\NormalTok{(countToFf}\OperatorTok{$}\NormalTok{Buy_Count)}
\NormalTok{maxCount2 =}\StringTok{ }\KeywordTok{max}\NormalTok{(newSet2[}\KeywordTok{complete.cases}\NormalTok{(newSet2)])}
\NormalTok{minCount2 =}\StringTok{ }\KeywordTok{min}\NormalTok{(newSet2[}\KeywordTok{complete.cases}\NormalTok{(newSet2)])}
\NormalTok{countToFf <-}\StringTok{ }\KeywordTok{subset}\NormalTok{(countToFf, Buy_Count}\OperatorTok{<}\NormalTok{maxCount2 }\OperatorTok{&}\StringTok{ }\NormalTok{Buy_Count}\OperatorTok{>}\NormalTok{minCount2)}
\CommentTok{#descdist(countToFf$Buy_Count, boot= 500, discrete=TRUE, graph=FALSE)}
\KeywordTok{descdist}\NormalTok{(countToFf}\OperatorTok{$}\NormalTok{Buy_Count, }\DataTypeTok{boot=}\DecValTok{500}\NormalTok{, }\DataTypeTok{graph=}\OtherTok{FALSE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## summary statistics
## ------
## min:  32   max:  639 
## median:  84 
## mean:  140.8085 
## estimated sd:  128.0521 
## estimated skewness:  2.035078 
## estimated kurtosis:  7.463705
\end{verbatim}

\subsubsection{Approximating the buying
distributions}\label{approximating-the-buying-distributions}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{distributionFit_Buyer_pois <-}\StringTok{ }\KeywordTok{fitdist}\NormalTok{(countToFf}\OperatorTok{$}\NormalTok{Buy_Count, }\StringTok{"pois"}\NormalTok{, }\DataTypeTok{method =}\StringTok{"mle"}\NormalTok{)}
\NormalTok{distributionFit_Buyer_wb <-}\StringTok{ }\KeywordTok{fitdist}\NormalTok{(countToFf}\OperatorTok{$}\NormalTok{Buy_Count, }\StringTok{"weibull"}\NormalTok{, }\DataTypeTok{method =}\StringTok{"mle"}\NormalTok{)}
\NormalTok{distributionFit_Buyer_ln <-}\StringTok{ }\KeywordTok{fitdist}\NormalTok{(countToFf}\OperatorTok{$}\NormalTok{Buy_Count, }\StringTok{"lnorm"}\NormalTok{, }\DataTypeTok{method =}\StringTok{"mle"}\NormalTok{)}
\NormalTok{distributionFit_Buyer_gm <-}\StringTok{ }\KeywordTok{fitdist}\NormalTok{(countToFf}\OperatorTok{$}\NormalTok{Buy_Count, }\StringTok{"gamma"}\NormalTok{, }\DataTypeTok{method =}\StringTok{"mme"}\NormalTok{)}
\CommentTok{#distributionFit_Buyer_pois$loglik}
\CommentTok{#plot(distributionFit_Buyer_pois)}
\CommentTok{#distributionFit_Buyer_wb$loglik}
\CommentTok{#plot(distributionFit_Buyer_wb)}
\CommentTok{#distributionFit_Buyer_ln$loglik}
\CommentTok{#plot(distributionFit_Buyer_ln)}
\CommentTok{#distributionFit_Buyer_gm$loglik}
\CommentTok{#plot(distributionFit_Buyer_gm)}
\end{Highlighting}
\end{Shaded}

\subsubsection{Study 1: Conclusion}\label{study-1-conclusion}

From the above graph estimates, both buy and sell frequency for our
dataset follows LOG-NORMAL distribution as the log likelihood value is
maximum and standard error is least and the emperical distribution curve
follows the theoritical distribution curve for the log-normal graph most
accurately.

\subsection{Study 3:}\label{study-3}

We find the most active users in BNB token and try to fit a distribution
for their activities among all the tokens throughout given dataset. We
take into consideration anyone who is buying or selling the token as we
are interested in all activities.

\subsubsection{Getting the active users}\label{getting-the-active-users}

We first find out the most active users for our token. Active users are
selected as those users who buy/sell BNB token more than the average
count of all users buying/selling BNB token. This is done to get enough
data points for fitting the distrbution later on.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{allUsers <-}\StringTok{ }\KeywordTok{append}\NormalTok{(mydata}\OperatorTok{$}\NormalTok{TONODE, mydata}\OperatorTok{$}\NormalTok{FROMNODE)}
\NormalTok{allUsers <-}\StringTok{ }\KeywordTok{data.frame}\NormalTok{(allUsers)}
\KeywordTok{colnames}\NormalTok{(allUsers) <-}\StringTok{ }\KeywordTok{c}\NormalTok{(}\StringTok{"USERS"}\NormalTok{)}

\NormalTok{usersFreq <-}\StringTok{ }\KeywordTok{count}\NormalTok{(allUsers, }\StringTok{"USERS"}\NormalTok{)}
\NormalTok{meanFreq <-}\StringTok{ }\KeywordTok{mean}\NormalTok{(usersFreq}\OperatorTok{$}\NormalTok{freq)}
\NormalTok{activeUsers <-}\StringTok{ }\NormalTok{usersFreq[(usersFreq}\OperatorTok{$}\NormalTok{freq}\OperatorTok{>}\NormalTok{meanFreq),]}
\end{Highlighting}
\end{Shaded}

\subsubsection{Reading all other token
data}\label{reading-all-other-token-data}

We go thorugh all the other tokens in given dataset and find out how
many tokens each user buys/sells

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{col_names <-}\StringTok{ }\KeywordTok{c}\NormalTok{(}\StringTok{"FROMNODE"}\NormalTok{,}\StringTok{"TONODE"}\NormalTok{,}\StringTok{"DATE"}\NormalTok{,}\StringTok{"TOKENAMOUNT"}\NormalTok{)}
\NormalTok{fpath<-}\StringTok{"/Users/pushpitapanigrahi/Desktop/PushpitaFiles/Study/4.StatsForDS/Proj1/Ethereum token graphs"}
\NormalTok{files <-}\StringTok{ }\KeywordTok{list.files}\NormalTok{(}\DataTypeTok{path=}\NormalTok{fpath, }\DataTypeTok{pattern=}\StringTok{"*.txt"}\NormalTok{, }\DataTypeTok{full.names=}\OtherTok{TRUE}\NormalTok{, }\DataTypeTok{recursive=}\OtherTok{FALSE}\NormalTok{)}

\NormalTok{uniqueUsersForAllTokens <-}\StringTok{ }\KeywordTok{list}\NormalTok{() }\CommentTok{#For every token a user transacts in, there is one entry of the userId in this list}
\ControlFlowTok{for}\NormalTok{(i }\ControlFlowTok{in} \DecValTok{1}\OperatorTok{:}\KeywordTok{length}\NormalTok{(files))\{}
\NormalTok{  t <-}\StringTok{ }\KeywordTok{data.frame}\NormalTok{(}\KeywordTok{read.csv}\NormalTok{( files[i], }\DataTypeTok{header =} \OtherTok{FALSE}\NormalTok{, }\DataTypeTok{sep =} \StringTok{" "}\NormalTok{, }\DataTypeTok{dec =} \StringTok{"."}\NormalTok{, }\DataTypeTok{col.names =}\NormalTok{ col_names))}
\NormalTok{  tusers <-}\StringTok{ }\KeywordTok{unique}\NormalTok{(}\KeywordTok{append}\NormalTok{(t}\OperatorTok{$}\NormalTok{FROMNODE, t}\OperatorTok{$}\NormalTok{TONODE))}
\NormalTok{  uniqueUsersForAllTokens <-}\StringTok{ }\KeywordTok{append}\NormalTok{(uniqueUsersForAllTokens,tusers)}
\NormalTok{\}}
\NormalTok{usersFromAllTokens <-}\StringTok{ }\KeywordTok{do.call}\NormalTok{(rbind.data.frame, uniqueUsersForAllTokens)}
\KeywordTok{colnames}\NormalTok{(usersFromAllTokens)<-}\KeywordTok{c}\NormalTok{(}\StringTok{"USERID"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\subsubsection{Counting the number of tokens per
userid}\label{counting-the-number-of-tokens-per-userid}

We now reverse the frequency count, to find how many unique tokens each
user id is transacting in. Below is a snipet of resulting data:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{userTokenCount <-}\StringTok{ }\KeywordTok{data.frame}\NormalTok{(}\KeywordTok{table}\NormalTok{(usersFromAllTokens}\OperatorTok{$}\NormalTok{USERID[usersFromAllTokens}\OperatorTok{$}\NormalTok{USERID }\OperatorTok{%in%}\StringTok{ }\NormalTok{activeUsers}\OperatorTok{$}\NormalTok{USERS]))}
\KeywordTok{colnames}\NormalTok{(userTokenCount) <-}\StringTok{  }\KeywordTok{c}\NormalTok{(}\StringTok{"USERID"}\NormalTok{, }\StringTok{"COUNT"}\NormalTok{)}
\CommentTok{#head(userTokenCount)}
\NormalTok{freqOfTokenCount <-}\StringTok{ }\KeywordTok{count}\NormalTok{(userTokenCount, }\StringTok{"COUNT"}\NormalTok{)}
\KeywordTok{colnames}\NormalTok{(freqOfTokenCount) <-}\StringTok{ }\KeywordTok{c}\NormalTok{(}\StringTok{"Users_Count"}\NormalTok{, }\StringTok{"Freq_Count"}\NormalTok{)}
\CommentTok{#head(freqOfTokenCount)}
\KeywordTok{plot}\NormalTok{(freqOfTokenCount}\OperatorTok{$}\NormalTok{Users_Count, freqOfTokenCount}\OperatorTok{$}\NormalTok{Freq_Count)}
\end{Highlighting}
\end{Shaded}

\includegraphics{Report_files/figure-latex/unnamed-chunk-13-1.pdf}

\subsubsection{Removing outliers and summarizing unique token counts for
the active
users}\label{removing-outliers-and-summarizing-unique-token-counts-for-the-active-users}

We use the same Culley and Fray graph software to find the distributions
our data approximately fits into.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{newSet3 <-}\StringTok{ }\KeywordTok{remove_outliers}\NormalTok{(freqOfTokenCount}\OperatorTok{$}\NormalTok{Freq_Count)}
\NormalTok{maxCount3 =}\StringTok{ }\KeywordTok{max}\NormalTok{(newSet3[}\KeywordTok{complete.cases}\NormalTok{(newSet3)])}
\NormalTok{minCount3 =}\StringTok{ }\KeywordTok{min}\NormalTok{(newSet3[}\KeywordTok{complete.cases}\NormalTok{(newSet3)])}
\NormalTok{freqOfTokenCount <-}\StringTok{ }\KeywordTok{subset}\NormalTok{(freqOfTokenCount, Freq_Count}\OperatorTok{<}\NormalTok{maxCount3 }\OperatorTok{&}\StringTok{ }\NormalTok{Freq_Count}\OperatorTok{>}\NormalTok{minCount3)}
\CommentTok{#descdist(freqOfTokenCount$Freq_Count, boot= 500, discrete=TRUE, graph=FALSE)}
\KeywordTok{descdist}\NormalTok{(freqOfTokenCount}\OperatorTok{$}\NormalTok{Freq_Count, }\DataTypeTok{boot=} \DecValTok{500}\NormalTok{, }\DataTypeTok{graph=}\OtherTok{FALSE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## summary statistics
## ------
## min:  2   max:  658 
## median:  30 
## mean:  113.9565 
## estimated sd:  173.3594 
## estimated skewness:  2.04776 
## estimated kurtosis:  6.948924
\end{verbatim}

\subsubsection{Fitting the distrubution to find the closest
fit}\label{fitting-the-distrubution-to-find-the-closest-fit}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{distributionFit_Count_pois <-}\StringTok{ }\KeywordTok{fitdist}\NormalTok{(freqOfTokenCount}\OperatorTok{$}\NormalTok{Freq_Count, }\StringTok{"pois"}\NormalTok{, }\DataTypeTok{method =}\StringTok{"mle"}\NormalTok{)}
\NormalTok{distributionFit_Count_wb <-}\StringTok{ }\KeywordTok{fitdist}\NormalTok{(freqOfTokenCount}\OperatorTok{$}\NormalTok{Freq_Count, }\StringTok{"weibull"}\NormalTok{, }\DataTypeTok{method =}\StringTok{"mle"}\NormalTok{)}
\NormalTok{distributionFit_Count_ln <-}\StringTok{ }\KeywordTok{fitdist}\NormalTok{(freqOfTokenCount}\OperatorTok{$}\NormalTok{Freq_Count, }\StringTok{"lnorm"}\NormalTok{, }\DataTypeTok{method =}\StringTok{"mle"}\NormalTok{)}
\NormalTok{distributionFit_Count_gm <-}\StringTok{ }\KeywordTok{fitdist}\NormalTok{(freqOfTokenCount}\OperatorTok{$}\NormalTok{Freq_Count, }\StringTok{"gamma"}\NormalTok{ ,}\DataTypeTok{method=}\StringTok{"mme"}\NormalTok{)}
\CommentTok{#distributionFit_Count_wb$loglik}
\CommentTok{#plot(distributionFit_Count_wb)}
\CommentTok{#distributionFit_Seller_pois$loglik}
\CommentTok{#plot(distributionFit_Count_pois)}
\CommentTok{#distributionFit_Seller_ln$loglik}
\CommentTok{#plot(distributionFit_Count_ln)}
\CommentTok{#distributionFit_Seller_gm$loglik}
\CommentTok{#plot(distributionFit_Count_gm)}
\end{Highlighting}
\end{Shaded}

\subsubsection{Study 3: Conclusion}\label{study-3-conclusion}

From the above graph estimates, the number of unique tokens in our
dataset in which the most active users of BNB token transact, follows a
weibull distribution as the log likelihood value is maximum, also the
emperical distribution curve follows the theoritical distribution curve
for the log-normal graph most accurately.

\subsection{Study 2:}\label{study-2}

Here the aim is to select a feature and select a criteria for creating
layers of transaction and finding the correlation of price data for BNB
token among the layers. We find the correlation between the unique
number of buyers(feature) in each day(layer) to the token opening price
for the day. We select the layers to be a day as that is the minimum
division available within the dataset. This study will help
understanding the degree of correlation between how user activities
model with respect to the opening price of the token in each day.

\subsubsection{Studying distribution of the opening price
.}\label{studying-distribution-of-the-opening-price-.}

Study the pattern for opening price values on each day for BNB token. We
do not see any outliers in this data.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{timePrices <-}\StringTok{ }\KeywordTok{subset}\NormalTok{(myPrices, }\DataTypeTok{select=}\KeywordTok{c}\NormalTok{(}\StringTok{"Date"}\NormalTok{,}\StringTok{"Open"}\NormalTok{))}
\NormalTok{timePrices}\OperatorTok{$}\NormalTok{Date <-}\StringTok{ }\KeywordTok{as.Date}\NormalTok{(timePrices}\OperatorTok{$}\NormalTok{Date, }\StringTok{"%Y-%m-%d"}\NormalTok{)}
\NormalTok{timePrices <-}\StringTok{ }\KeywordTok{unique}\NormalTok{(timePrices)}
\CommentTok{#summary(timePrices)}
\KeywordTok{plot}\NormalTok{(timePrices}\OperatorTok{$}\NormalTok{Date, timePrices}\OperatorTok{$}\NormalTok{Open, }\DataTypeTok{main =} \StringTok{"Opening prices VS date"}\NormalTok{, }\DataTypeTok{xlab =} \StringTok{"Date"}\NormalTok{, }\DataTypeTok{ylab=}\StringTok{"Open price"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{Report_files/figure-latex/unnamed-chunk-16-1.pdf}

\subsubsection{Studying the distribution of number of unique buyers each
day.}\label{studying-the-distribution-of-number-of-unique-buyers-each-day.}

Study the pattern of how many unique buyers are there for our token each
day. We see outliers in this data.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{timeBuyFreq <-}\StringTok{ }\KeywordTok{ddply}\NormalTok{(mydata, .(DATE), mutate, }\DataTypeTok{count =} \KeywordTok{length}\NormalTok{(}\KeywordTok{unique}\NormalTok{(TONODE)))}
\NormalTok{timeBuyFreq <-}\StringTok{ }\KeywordTok{subset}\NormalTok{(timeBuyFreq, }\DataTypeTok{select=}\KeywordTok{c}\NormalTok{(}\StringTok{"DATE"}\NormalTok{, }\StringTok{"count"}\NormalTok{))}
\NormalTok{timeBuyFreq}\OperatorTok{$}\NormalTok{DATE <-}\StringTok{ }\KeywordTok{as.Date}\NormalTok{(timeBuyFreq}\OperatorTok{$}\NormalTok{DATE, }\StringTok{"%Y-%m-%d"}\NormalTok{)}
\NormalTok{timeBuyFreq <-}\StringTok{ }\KeywordTok{unique}\NormalTok{(timeBuyFreq)}
\CommentTok{#summary(timeBuyFreq)}
\NormalTok{outliers <-}\StringTok{ }\KeywordTok{boxplot}\NormalTok{(timeBuyFreq}\OperatorTok{$}\NormalTok{count, }\DataTypeTok{main=}\StringTok{"Unique buyer count distribution"}\NormalTok{, }\DataTypeTok{ylab=}\StringTok{"unique buyer count"}\NormalTok{)}\OperatorTok{$}\NormalTok{out}
\end{Highlighting}
\end{Shaded}

\includegraphics{Report_files/figure-latex/unnamed-chunk-17-1.pdf}

We see the summary of the outliers and plot the data with and without
the outliers.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{#summary(outliers)}
\KeywordTok{plot}\NormalTok{( timeBuyFreq}\OperatorTok{$}\NormalTok{DATE, timeBuyFreq}\OperatorTok{$}\NormalTok{count ,}\DataTypeTok{ylim=}\KeywordTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{, }\DecValTok{633}\NormalTok{), }\DataTypeTok{main =} \StringTok{"Unique buyer count VS date"}\NormalTok{, }\DataTypeTok{xlab =} \StringTok{"Date"}\NormalTok{, }\DataTypeTok{ylab=}\StringTok{"Unique buyer count"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{Report_files/figure-latex/unnamed-chunk-19-1.pdf}

\subsubsection{Combine opening price and unique buyer count for each
day}\label{combine-opening-price-and-unique-buyer-count-for-each-day}

We remove the outliers and merge the price and buyer counts to find the
pearson correlation between the two fields with each day being a layer.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{priceSellForEachDay <-}\StringTok{ }\KeywordTok{merge}\NormalTok{(}\DataTypeTok{x=}\NormalTok{timePrices, }\DataTypeTok{y=}\NormalTok{timeBuyFreq, }\DataTypeTok{by.x=}\KeywordTok{c}\NormalTok{(}\StringTok{"Date"}\NormalTok{), }\DataTypeTok{by.y =} \KeywordTok{c}\NormalTok{(}\StringTok{"DATE"}\NormalTok{))}
\NormalTok{newSet <-}\StringTok{ }\KeywordTok{remove_outliers}\NormalTok{(priceSellForEachDay}\OperatorTok{$}\NormalTok{count)}
\NormalTok{maxCount =}\StringTok{ }\KeywordTok{max}\NormalTok{(newSet[}\KeywordTok{complete.cases}\NormalTok{(newSet)])}
\NormalTok{minCount =}\StringTok{ }\KeywordTok{min}\NormalTok{(newSet[}\KeywordTok{complete.cases}\NormalTok{(newSet)])}
\NormalTok{priceSellForEachDay <-}\StringTok{ }\KeywordTok{subset}\NormalTok{(priceSellForEachDay, count}\OperatorTok{<}\NormalTok{maxCount }\OperatorTok{&}\StringTok{ }\NormalTok{count}\OperatorTok{>}\NormalTok{minCount)}
\CommentTok{#head(priceSellForEachDay)}
\KeywordTok{cor}\NormalTok{(priceSellForEachDay}\OperatorTok{$}\NormalTok{Open, priceSellForEachDay}\OperatorTok{$}\NormalTok{count, }\DataTypeTok{method=}\KeywordTok{c}\NormalTok{(}\StringTok{"pearson"}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0.7335533
\end{verbatim}

\subsubsection{Study 2: Conclusion}\label{study-2-conclusion}

We find a very strong positive correlation between the number of people
buying BNB token in a day to the price of the token that day. This menas
that user decisions get highly effected by the opening price of bnb
token on that day. So we combine both plots to visualize the
correlation.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{#' Create the two plots.}
\NormalTok{p1 <-}\StringTok{ }\KeywordTok{ggplot}\NormalTok{(priceSellForEachDay, }\KeywordTok{aes}\NormalTok{(Date, count)) }\OperatorTok{+}\StringTok{ }\KeywordTok{geom_line}\NormalTok{() }\OperatorTok{+}\StringTok{ }\KeywordTok{theme_minimal}\NormalTok{() }\OperatorTok{+}\StringTok{ }
\StringTok{      }\KeywordTok{theme}\NormalTok{(}\DataTypeTok{axis.title.x =} \KeywordTok{element_blank}\NormalTok{(), }\DataTypeTok{axis.text.x =} \KeywordTok{element_blank}\NormalTok{())}
\NormalTok{p2 <-}\StringTok{ }\KeywordTok{ggplot}\NormalTok{(priceSellForEachDay,}\KeywordTok{aes}\NormalTok{(Date, Open)) }\OperatorTok{+}\StringTok{ }\KeywordTok{geom_bar}\NormalTok{(}\DataTypeTok{stat=}\StringTok{"identity"}\NormalTok{) }\OperatorTok{+}\StringTok{ }\KeywordTok{theme_minimal}\NormalTok{() }\OperatorTok{+}\StringTok{ }
\StringTok{      }\KeywordTok{theme}\NormalTok{(}\DataTypeTok{axis.title.x =} \KeywordTok{element_blank}\NormalTok{(),}\DataTypeTok{axis.text.x =} \KeywordTok{element_text}\NormalTok{(}\DataTypeTok{angle=}\DecValTok{90}\NormalTok{))}
\KeywordTok{grid.newpage}\NormalTok{()}
\KeywordTok{grid.draw}\NormalTok{(}\KeywordTok{rbind}\NormalTok{(}\KeywordTok{ggplotGrob}\NormalTok{(p1), }\KeywordTok{ggplotGrob}\NormalTok{(p2), }\DataTypeTok{size =} \StringTok{"last"}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\includegraphics{Report_files/figure-latex/unnamed-chunk-21-1.pdf}


\end{document}
